# Speech_Emotion_Recognition ðŸš€ðŸŽµ
## Welcome to my project! ðŸŽ‰ ðŸš€ âœ¨  
This project is prepared to classify the audio files into specific emotions. ðŸŽµ  
There has been different kinds of datasets used in this project like **Ravdess**, **Crema**, **Tess**, **Savee**. All of these datasets contain different kinds of audio files and their corresponding emotions.   
To implement the project all of these datasets has been merged into a single dataset.  
After merged them to a single dataset, data analysis is done with the help of data visualization to identify some factors.  
Different kinds of preprocessing steps has been taken to preprocess the data like adding some noise, stretching, audio shifting and pitch in the existing audio files to help in classifying the audio.  
Adding to this, feature extraction also has been done with the help of zcr, rmse, mfcc which is used to find the zero crossing rate, root mean square error and Mel-Frequency Cepstral Coefficients to extract some important features from the audio data.  
After this, a cnn model has been trained with the help of the final dataset which is acheiving 96% accuracy which is a good enough for the classification task and after this we are getting a quite satisying result during prediction of the test dataset.  
The model has been saved for further use.  
Below is the flow chart of the entire work to inderstand it more properly.  
![Importing Libraries](https://github.com/user-attachments/assets/1843117a-fe98-4466-84cd-ba52ead3c595)
